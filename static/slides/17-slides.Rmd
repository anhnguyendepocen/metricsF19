---
title: "3.5: Causal Inference and DAGs"
subtitle: "ECON 480 · Econometrics · Fall 2019"
author: 'Ryan Safner<br> Assistant Professor of Economics <br> <a href="mailto:safner@hood.edu"><i class="fa fa-paper-plane fa-fw"></i> safner@hood.edu</a> <br> <a href="https://github.com/ryansafner/metricsf19"><i class="fa fa-github fa-fw"></i> ryansafner/metricsf19</a><br> <a href="https://metricsF19.classes.ryansafner.com"> <i class="fa fa-globe fa-fw"></i> metricsF19.classes.ryansafner.com</a><br>'
#date:
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML" # rescales math with css changes https://github.com/yihui/xaringan/issues/143
    lib_dir: libs
    df_print: paged
    #seal: false
    css: [custom.css, custom-fonts.css, "hygge"] #, metropolis, metropolis-fonts
    nature:
      beforeInit: ["macros.js", "https://platform.twitter.com/widgets.js"] # first is for rescaling images , second is for embedding tweets, https://github.com/yihui/xaringan/issues/100
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
    includes:
      in_header: header.html # for font awesome, used in title  
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo=F,
                      message=F,
                      warning=F)
library(tidyverse)
set.seed(256)
update_geom_defaults("label", list(family = "Fira Sans Condensed"))
```

# Causality

.pull-left[
- Statistics profession is obstinant that we cannot say anything about causality
  - Statisticians: causation is simply a subset of correlation, where correlation is $-1$ or $1$

- But you have to! It's how the human brain works!

- We can't concieve of (spurious) correlation without some causation

]

.pull-right[

.center[
![:scale 70%](https://www.dropbox.com/s/qp9m156rcxqp3nc/bookofwhy.jpg?raw=1)
]
]

---

background-image: url(https://www.dropbox.com/s/245ma3buawugeog/rctgoldstandard.png?raw=1)
background-size: cover

---

# RCTs are All the Rage

.pull-left[
.center[

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Professors Esther Duflo and Abhijit Banerjee, co-directors of MIT&#39;s <a href="https://twitter.com/JPAL?ref_src=twsrc%5Etfw">@JPAL</a>, receive congratulations on the big news this morning. They share in the <a href="https://twitter.com/hashtag/NobelPrize?src=hash&amp;ref_src=twsrc%5Etfw">#NobelPrize</a> in economic sciences “for their experimental approach to alleviating global poverty.”<br> <br>Photo: Bryce Vickmark <a href="https://t.co/NWeTrjR2Bq">pic.twitter.com/NWeTrjR2Bq</a></p>&mdash; Massachusetts Institute of Technology (MIT) (@MIT) <a href="https://twitter.com/MIT/status/1183752282988564480?ref_src=twsrc%5Etfw">October 14, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

]
]

.pull-right[
.center[

Source: [Vox (Oct 14, 2019)](https://www.vox.com/future-perfect/2019/10/14/20913928/nobel-prize-economics-duflo-banerjee-kremer)

![](https://www.dropbox.com/s/119oeqictaktgsw/voxnobelrcts.png?raw=1)

]
]

---

# But Not Everyone Agrees I

.left-column[

.center[
![:scale 75%](https://www.dropbox.com/s/z1mnxolnzhvuv27/deaton.jpg?raw=1)

Angus Deaton

Economics Nobel 2015
]

]
.right-column[

> The RCT is a useful tool, but I think that is a mistake to put method ahead of substance. I have written papers using RCTs. Like other methods of investigation, they are often useful, and, like other methods, they have dangers and drawbacks. Methodological prejudice can only tie our hands...**It is not true that an RCT, when feasible, will always do better than an observational study.** This should not be controversial [but] might still make some uncomfortable, particularly the second [statement]: (a) RCTs are affected by the same problems of inference and estimation that economists have faced using other methods, and (b) no RCT can ever legitimately claim to have established causality. **My theme is that RCTs have no special status, they have no exemption from the problems of inference that econometricians have always wrestled with, and there is nothing that they, and only they, can accomplish.**
]

.source[Deaton, Angus, 2019, "[Randomization in the Tropics Revisited: A Theme and Eleven Variations](https://scholar.princeton.edu/sites/default/files/deaton/files/deaton_randomization_revisited_v2_2019_01.pdf)," Working Paper]

---

# But Not Everyone Agrees II

.left-column[
.center[
![:scale 75%](https://www.dropbox.com/s/e6mbwn4oba8w7lx/pritchett.jpg?raw=1)

Lant Pritchett

]
]

.right-column[

> People keep saying that the recent Nobelists "studied global poverty." This is exactly wrong. They made a commitment to a method, not a subject, and their commitment to method prevented them from studying global poverty.

> At a conference at Brookings in 2008 Paul Romer (last years Nobelist) said: "You guys are like going to a doctor who says you have an allergy and you have cancer. With the skin rash we can divide you skin into areas and test variety of substances and identify with precision and some certainty the cause. Cancer we have some ideas how to treat it but there are a variety of approaches and since we cannot be sure and precise about which is best for you, we will ignore the cancer and not treat it."

]

.source[[Source](https://www.facebook.com/lant.pritchett/posts/10218688602381690)]

---

# But Not Everyone Agrees III

.left-column[

.center[
![:scale 75%](https://www.dropbox.com/s/z1mnxolnzhvuv27/deaton.jpg?raw=1)

Angus Deaton

Economics Nobel 2015
]

]
.right-column[

> "Lant Pritchett is so fun to listen to, sometimes you could forget that he is completely full of shit."

]

.source[[Source](https://medium.com/@ismailalimanik/lant-pritchett-the-debate-about-rcts-in-development-is-over-ec7a28a82c17)]


---

# RCTs and Evidence-Based Policy I

.pull-left[

- Programs *randomly* assign treatment to different individuals and measure causal effect of treatment

- **RAND Health Insurance Study**

- **Oregon Medicaid Expansion**

- **HUD's Moving to Opportunity**

- **Tennessee STAR**

]

.pull-right[
.center[
![](https://www.dropbox.com/s/j0kwzqb2ptusckt/madlaboratory.jpg?raw=1)
]
]

---

# RCTs and Evidence-Based Policy II

- Should we *ONLY* base policies on the evidence from Randomized Controlled Trials?

--

.pull-left[

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">|￣￣￣￣￣￣￣￣￣￣|<br> IF U DONT SMOKE,<br> U ALREADY <br> BELIEVE IN<br> CAUSAL INFERENCE<br> WITHOUT<br> RANDOMIZED TRIALS<br>|＿＿＿＿＿＿＿＿＿＿| <br> (\__/) ||<br> (•ㅅ•) ||<br> / 　 づ<a href="https://twitter.com/hashtag/HistorianSignBunny?src=hash&amp;ref_src=twsrc%5Etfw">#HistorianSignBunny</a> <a href="https://twitter.com/hashtag/Epidemiology?src=hash&amp;ref_src=twsrc%5Etfw">#Epidemiology</a></p>&mdash; Ellie Murray (@EpiEllie) <a href="https://twitter.com/EpiEllie/status/1017622949799571456?ref_src=twsrc%5Etfw">July 13, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

]

--

.pull-right[

.center[

Source: [British Medical Journal](https://www.bmj.com/content/363/bmj.k5094)

![](https://www.dropbox.com/s/9mimwcoamiv54tf/rctparachutesstudy.png?raw=1)
]

]

---

# RCTs and Evidence-Based Policy III

.pull-left[
.center[
![:scale 80%](https://www.dropbox.com/s/5ptmdhgeyerhr4a/rctparachutes1.jpg?raw=1)
]
]

--

.pull-right[
.center[
![:scale 80%](https://www.dropbox.com/s/3knd5wy8h4eyq1j/rctparachutes2.jpg?raw=1)
]

]

---

# Correlation and Causation I

.center[

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Correlation implies casuation,&quot; the dean whispered as he handed me my PhD.<br><br>&quot;But then why-&quot;<br><br>&quot;Because if they knew, they wouldn&#39;t need us.&quot;</p>&mdash; David Robinson (@drob) <a href="https://twitter.com/drob/status/877976063942512640?ref_src=twsrc%5Etfw">June 22, 2017</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

]

---

# Correlation and Causation II

.center[

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Causality isn&#39;t achieved; it&#39;s approached.</p>&mdash; John B. Holbein (@JohnHolbein1) <a href="https://twitter.com/JohnHolbein1/status/982635508089180161?ref_src=twsrc%5Etfw">April 7, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

]

---

# Correlation and Causation

.pull-left[
- .onfire[Correlation:]
  - Math & Statistics
  - Computers, AI, Machine learning can figure this out (even better than humans)

- .onfire[Causation:]
  - Philosophy, Intuition, Theory
  - .shout[Counterfactual thinking], unique to humans (vs. animals or machines)
  - Computers *cannot* yet figure this out

]

.pull-right[
.center[
![](https://www.dropbox.com/s/c91a06o91rf3e5h/causation.jpg?raw=1)
]
]

---

# Causation Requires Counterfactual Thinking

.pull-left[
.center[
![:scale 70%](https://www.dropbox.com/s/6n3dg3xpizsxpsj/ladderofcausation.png?raw=1)
]
]

.pull-right[
.center[
![:scale 70%](https://www.dropbox.com/s/qp9m156rcxqp3nc/bookofwhy.jpg?raw=1)
]
]

---

background-image: url(https://www.dropbox.com/s/zsx3pa4m51p82dj/twopaths.jpg?raw=1)
background-size: cover

---

# Recall: The Fundamental Problem of Causal Inference I

.left-column[

| John      | Maria     |
|-----------|-----------|
| ![](https://www.dropbox.com/s/5vh181yeg0p91t7/coldman2.jpg?raw=1) | ![](https://www.dropbox.com/s/7qa0gtuy29us4p2/femalejogger2.jpg?raw=1) |
| $Y_J^0=3$ | $Y_M^0=5$ | 
| $Y_J^1=4$ | $Y_M^1=5$ |
| $Y_J^1-Y_J^0=1$ | $Y_M^1-Y_M^0=0$ |
| $Y_J=(Y_J^1)=4$ | $Y_M=(Y_M^0)=5$ | 

]

.right-column[

- Recall example from [class 1.2](/class/02-class)

- John will choose to buy health insurance

- Maria will choose to not buy health insurance

- Health insurance improves John's score by 1, has no effect on Maria's score

- Note, all we can observe in the data are their health outcomes *after* they have chosen (not) to buy health insurance: $Y_J=4$ and $Y_M=5$

- .whisper[*Observed* difference] between John and Maria: $$Y_J-Y_M=-1$$
]

---

# Recall: Counterfactuals

.left-column[

| John      | Maria     |
|-----------|-----------|
| ![](https://www.dropbox.com/s/5vh181yeg0p91t7/coldman2.jpg?raw=1) | ![](https://www.dropbox.com/s/7qa0gtuy29us4p2/femalejogger2.jpg?raw=1) |
| $Y_J=4$ | $Y_M=5$ | 

This is all the data we *actually* observe
]

.right-column[
- Observed difference between John and Maria: 
$$Y_J-Y_M=\underbrace{Y^1_J-Y^0_M}_{=-1}$$

- Recall:
    - John has bought health insurance $(Y^1_J)$
    - Maria has not bought insurance $(Y^0_M)$

- We don't see the .shout[counterfactuals]: 
    - John's score *without* insurance
    - Maria score *with* insurance

]

---

# Causal Inference

.pull-left[

- We will seek to understand what causality *is* and how we can approach finding it

- We will also explore the different common .shout[research designs] meant to .whisper[identify] causal relationships

- **These skills**, more than supply & demand, constrained optimization models, ISLM, etc, **are the tools and comparative advantage of a modern research economist**
    - Why all big companies (especially in tech) have entire economics departments in them

]

.pull-right[

.center[
![](https://www.dropbox.com/s/yw8t5xsa8dgei71/coding.jpeg?raw=1)
]
]

---

# Clever Research Designs Identify Causality

```{r, fig.retina=3, fig.align="center", out.width="60%"}
ggplot(data = tibble(x=c(0,10),
                     y=c(0,10)))+
  aes(x = x,
      y = y)+
  geom_label(x=1,y=2, label="Correlation", size =10, color = "#fde0dd")+
  geom_label(x=5,y=2, label="Causation", size = 10, color = "#7a0177")+
  
  
  geom_label(x=1,y=4, label="Differences", size =5, color = "#fde0dd")+
  geom_label(x=1,y=3.5, label="Pre-Post", size =5, color = "#fde0dd")+
  geom_label(x=2,y=4.5, label="Multiple Regression", size =5, color = "#fbb4b9")+
  geom_label(x=2,y=3.5, label="Matching", size =5, color = "#fbb4b9")+
    geom_label(x=3,y=5, label="Fixed Effects", size =5, color = "#f768a1")+
    geom_label(x=3.5,y=4.5, label="Diff-in-Diff", size =5, color = "#c51b8a")+
  geom_label(x=4,y=3.5, label="Natural Experiments", size =5, color = "#c51b8a")+
  geom_label(x=3.5,y=4, label="Regression Discontinuity", size =5, color = "#c51b8a")+
  geom_label(x=5,y=4.5, label="RCTs", size =5, color = "#7a0177")+
  annotate("segment", x = 1, xend = 5, y = 3, yend = 3, colour = "black", size=2, alpha=1, arrow=arrow(length=unit(0.5,"cm"), ends="last", type="closed"))+
  scale_x_continuous(breaks=seq(0,6,1),
                     limits=c(0,6))+
  scale_y_continuous(breaks=seq(1,5,1),
                     limits=c(1,5))+
  theme_void()
    

```

---

# What Then IS Causation?

.pull-left[

- $X$ causes $Y$ if we can intervene and change $X$ without changing anything else, and $Y$ changes
- $Y$ "listens to" $X$
    - $X$ may not be the only thing that causes $Y$

]

.pull-right[
.center[
![:scale 80%](https://www.dropbox.com/s/6w66jcc9gmw3hw4/lightswitch.jpg?raw=1)
]
]

---

# What Then IS Causation?

.pull-left[

- $X$ causes $Y$ if we can intervene and change $X$ without changing anything else, and $Y$ changes
- $Y$ "listens to" $X$
    - $X$ may not be the only thing that causes $Y$

.content-box-green[
.green[**Example**]

If $X$ is a light switch, and $Y$ is a light:

- Flipping the switch $(X)$ causes the light to go on $(Y)$
- But NOT if the light is burnt out (No $Y$ despite $X$)
- OR if the light was already on $(Y$ without $X$)
]

]

.pull-right[
.center[
![:scale 80%](https://www.dropbox.com/s/6w66jcc9gmw3hw4/lightswitch.jpg?raw=1)
]
]

---

# Less-Clear Causal Claims

.content-box-green[
.green[**Example**]

- Getting a college degree raises your wages

]

--

.content-box-green[
.green[**Example**]

- Tariffs reduce the volume of international trade

]

---

# Non-Causal Claims 

- All of the following have non-zero correlations. Are they causal?

.content-box-green[
.green[**Example**]

- Greater ice cream sales cause more violent crime
- Rooster crows cause the sun to rise in the morning

]

--

- Less clear: 

.content-box-green[
.green[**Example**]

- Colds tend to clear up a few days after you take Vitamin-C
- The economy performs better or worse depending on the political party in power

]

---

# Counterfactuals

- The *sine qua non* of causal claims are .shout[counterfactuals]: what would $Y$ have been if $X$ had been different?
- It is **impossible** to make a counterfactual claim from data alone! Need a causal model of the data-generating process!

---

# Counterfactuals and RCTs

- Again, RCTs are invoked as the gold standard for their ability to make counterfactual claims:
- Treatment/intervention $(X)$ is *randomly assigned* to individuals, and then outcome $Y$ is measured

> If person i who recieved treatment *had not recieved* the treatment, we can predict what his outcome *would have been*

> If person j who did not recieve treatment *had recieved treatment*, we can predict what her outcome *would have been*

- We can say this because, on average, treatment and control groups are *the same before treatment*

---

# From RCTs to Causal Models

- RCTs are but the best-known method of a large, growing science of .shout[causal inference]
- We need a .shout[causal model] to describe the .shout[data-generating process (DGP)]
- Requires us to make some .whisper[assumptions]


---

class: inverse, center, middle

# Causal Diagrams

---

# Causal Diagrams/DAGs

.pull-left[
- A surprisingly simple, yet rigorous and powerful method of modeling is using a .shout[causal diagram] or .shout[Directed Acyclic Graph (DAG)]

- A simple series of nodes (variables) connected by arrows that indicate causal effects
    - Arrows can only go one way ("directed") and can never loop back ("acyclic")
]

.pull-right[
```{r, echo = F, warning = F, message = F, fig.retina = 2, fig.align = "center"}
library("ggdag")

dagify(Y ~ X, Y ~ M, M ~ X, Y ~ Z, X ~ U, Z ~ U) %>% 
  ggdag_parents("Y", layout = "circle", stylized = F)+theme_dag_blank()+
  theme(legend.position = "none")

```
]

---

# Drawing a DAG

- Causal diagram (DAG) is the *model* of what you think the data-generating process is

- Useful to help figure out how to *identify* particular relationships of interest

- Requires some common sense/economic intutition

- Remember, all models are wrong, we just need them to be *useful*!

---

# Drawing a DAG: Example

.pull-left[

- Suppose we have data on three variables
  - `IP`: how much a firm spends on IP lawsuits 
  - `tech`: whether a firm is in tech industry
  - `profit`: firm profits

- They are all correlated with each other, but what's are the causal relationships? 

- We need our own **causal model** (from theory, intuition, etc) to sort
  - Data alone will not tell us!
]

.pull-right[

```{r, fig.retina=3, outwidth="90%", fig.align="center"}
library(ggdag)
#theme_set(theme_dag_blank())
library(gridExtra)

h1 <- dagify(profit ~ tech+ip,
             tech ~ ip,
             coords=list(
               x=c(tech=1, ip=2, profit=3),
               y=c(tech=1, ip=2, profit=1)
               )) %>% ggdag(stylized = FALSE)+
  labs(title = "1")+
  theme_void()+theme(legend.position = "none")

h2 <- dagify(profit ~ tech+ip,
             ip ~ tech,
             coords=list(
               x=c(tech=1, ip=2, profit=3),
               y=c(tech=1, ip=2, profit=1)
               )) %>% ggdag(stylized = FALSE)+
  labs(title = "2")+
  theme_void()+theme(legend.position = "none")

h3 <- dagify(profit ~ tech,
             ip ~ tech+profit,
             coords=list(
               x=c(tech=1, ip=2, profit=3),
               y=c(tech=1, ip=2, profit=1)
               )) %>% ggdag(stylized = FALSE)+
  labs(title = "3")+
  theme_void()+theme(legend.position = "none")

h4 <- dagify(profit ~ ip,
             tech ~ ip+profit,
             coords=list(
               x=c(tech=1, ip=2, profit=3),
               y=c(tech=1, ip=2, profit=1)
               )) %>% ggdag(stylized = FALSE)+
  labs(title = "4")+
  theme_void()+theme(legend.position = "none")

h5 <- dagify(tech ~ ip+profit,
             ip ~ profit,
             coords=list(
               x=c(tech=1, ip=2, profit=3),
               y=c(tech=1, ip=2, profit=1)
               )) %>% ggdag(stylized = FALSE)+
  labs(title = "5")+
  theme_void()+theme(legend.position = "none")

h6 <- dagify(tech ~ profit,
             ip ~ profit+tech,
             coords=list(
               x=c(tech=1, ip=2, profit=3),
               y=c(tech=1, ip=2, profit=1)
               )) %>% ggdag(stylized = FALSE)+
  labs(title = "6")+
  theme_void()+theme(legend.position = "none")

grid.arrange(h1, h2, h3, h4, h5, h6, ncol=2)

```
]

---

# Drawing a DAG: 

.pull-left[

1. Consider all the variables likely to be important to the data-generating process (including variables we can't observe!)

2. For simplicity, combine some similar ones together or prune those that aren't very important

3. Consider which variables are likely to affect others, and draw arrows connecting them

4. Test some testable implications of the model (to see if we have a correct one!)

]

.pull-right[

.center[
![](https://www.dropbox.com/s/v5vwsadw5vs448t/causality.jpg?raw=1)
]
]

---

# Side Notes

.pull-left[

- Drawing an arrow requires a direction - making a statement about causality!

- *Omitting* an arrow makes an equally important statement too!
  - In fact, we will *need* omitted arrows to show causality!

- If two variables are correlated, but neither causes the other, it's likely they are both caused by another (perhaps unobserved) variable - add it!

- There should be no *cycles* or *loops* (if so, there's probably another missing variable, such as time)

]

.pull-right[
.center[
![](https://www.dropbox.com/s/v5vwsadw5vs448t/causality.jpg?raw=1)
]
]
---

# DAG Example I

.pull-left[

.content-box-green[
.green[**Example**]: what is the effect of education on wages?
]

- Education ("treatment" or "exposure")

- Wages ("outcome" or "response")
]

.pull-right[

```{r, echo = F}
dagify(wage~educ) %>% 
  ggdag_parents("wage", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# DAG Example I

.pull-left[

- What other variables are important?
  - Ability
  - Socioeconomic status
  - Demographics
  - Phys. Ed. requirements
  - Year of birth
  - Location
  - Schooling laws
  - Job connections
]

.pull-right[

```{r, echo = F}
dagify(wage~educ) %>% 
  ggdag_parents("wage", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# DAG Example I

.pull-left[

- In social science and complex systems, 1000s of variables could plausibly be in DAG!

- So simplify:
  - Ignore trivial things (Phys. Ed. requirement)
  - Combine similar variables (Socioeconomic status, Demographics, Location $\rightarrow$ Background)
]

.pull-right[

```{r, echo = F}
dagify(wage~educ) %>% 
  ggdag_parents("wage", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# DAG Example II

.pull-left[

- Background, Year of birth, Location, Compulsory schooling, all cause education

- Background, year of birth, location, job connections probably cause wages
]

.pull-right[

```{r, echo = F}
dagify(wage~educ+conx+year+bckg+loc,
       educ~bckg+year+loc+laws) %>%
  ggdag_parents("wage", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# DAG Example III

.pull-left[

- Background, Year of birth, Location, Compulsory schooling, all cause education

- Background, year of birth, location, job connections probably cause wages

- Job connections in fact is probably caused by education!

- Location and background probably both caused by unobserved factor `(u1)`
]

.pull-right[

```{r, echo = F}
dagify(wage~educ+conx+year+bckg+loc,
       educ~bckg+year+loc+laws,
       conx~educ,
       bckg~u1,
       loc~u1) %>% 
  ggdag_parents("wage", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# DAG Example IV

.pull-left[

- This is messy, but we have a causal model!

- Makes our assumptions **explicit**, and many of them are **testable**

- DAG suggests certain relationships that will *not* exist:
  - all relationships between `laws` and `conx` go through `educ`
  - so if we controlled for `educ`, then `cor(laws,conx)` should be zero!
]

.pull-right[

```{r, echo = F}
dagify(wage~educ+conx+year+bckg+loc,
       educ~bckg+year+loc+laws,
       conx~educ,
       bckg~u1,
       loc~u1) %>% 
  ggdag_parents("wage", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# Let the Computer Do It: Dagitty.net I

.pull-left[
.center[

![](https://www.dropbox.com/s/zhqgfyvk2x4z863/dagitty.png?raw=1)
]
]

.pull-right[

- [Dagitty.net](http://dagitty.net) is a great tool to make these and give you testable implications

- Click `Model -> New Model`

- Name your "exposure" variable $(X$ of interest) and "outcome" variable $(Y)$

]

---

# Let the Computer Do It: Dagitty.net II

.pull-left[
.center[

![](https://www.dropbox.com/s/qu6839emzoitb1c/dagittyex1.png?raw=1)
]
]

.pull-right[

- Click and drag to move nodes around

- Add a new variable by double-clicking

- Add an arrow by double-clicking one variable and then double-clicking on the target (do again to remove arrow)

]

---

# Let the Computer Do It: Dagitty.net III

.pull-left[
.center[

![](https://www.dropbox.com/s/a55b66p8i4znjto/dagittyex2.png?raw=1)
]
]

.pull-right[

- Tells you **how to identify your effect**! (upper right)

> Minimal sufficient adjustment sets containing background, location, year for estimating the total effect of educ on wage:
background, location, year

- Tells you **some testable implications** (middle right)
  - *conditional independencies*, take the last one:
  - `job_connections` $\perp$ `year` | `educ`
  - means: holding constant `educ`, there should be no correlation between `job_connections` and `year` - can test this with data!

]

---

# Implications

- In order to .onfire[identify] the effect of education on wages, our model implies we need to control for background, location, and year
  - note: we do *not* need to control for anything else!

--

- How to control for them?
  - many ways, we've learned one: multivariate regression:
  
--

$$wages=\beta_0+\beta_1 \, educ + \beta_2 \, background + \beta_3 \, location + \beta_4 \, year$$

--

- How did Dagitty know what we needed to do? Some simple rules (below)

---

# Causal Effect

.pull-left[
.center[

![](https://www.dropbox.com/s/o7h0zbpvej0zuf5/dagittycontrolled.png?raw=1)
]
]

.pull-right[

- If we control for `background`, `location`, and `year`, we can **identify** the causal effect of `educ` $\rightarrow$ `wage`.


]

---


# You Can Draw DAGs In R

.pull-left[

- New package: `ggdag`
- Arrows are made with formula notation: `Y~X` means "`Y` is caused by `X`"

```{r, echo = T, eval=F}
library(ggdag)
dagify(wage~educ+conx+year+bckg+loc,
       educ~bckg+year+loc+laws,
       conx~educ,
       bckg~u1,
       loc~u1) %>% 
  ggdag()+
  theme_dag()
```
]

.pull-right[

```{r, echo = F}
dagify(wage~educ+conx+year+bckg+loc,
       educ~bckg+year+loc+laws,
       conx~educ,
       bckg~u1,
       loc~u1) %>% 
  ggdag(stylized = FALSE)+
  theme_dag_blank()
```

]

---

class: inverse, center, middle

# DAG Rules

---

# DAGs I

.pull-left[

- Typical notation: 

- $X$ is independent variable of interest
  - Epidemiology: .onfire["intervention"]

- $Y$ is dependent/.onfire["response"] variable

- Other variables use other letters
]

.pull-right[

```{r, echo = F, fig.retina = 2, fig.align="center"}
dagify(Y~X,
                coords=list(
                x=c(X=1,Y=2),
                y=c(X=1,Y=1)
              )) %>% 
  tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```
]

---

# DAGs and Causal Effects

.pull-left[

- Arrows indicate causal effect (in proper direction)

- Two types of causal effect:
    1. Direct effects $X \rightarrow Y$
]

.pull-right[

```{r, echo = F, fig.retina = 2, fig.align="center"}
dagify(Y~X,
                coords=list(
                x=c(X=1,Y=2),
                y=c(X=1,Y=1)
              )) %>% 
  tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```


]

---

# DAGs and Causal Effects

.pull-left[

- Arrows indicate causal effect (in proper direction)

- Two types of causal effect:

1. Direct effects $X \rightarrow Y$

2. Indirect effects $X \rightarrow M \rightarrow Y$ 
  - $M$ is a "mediator" variable, the mechanism by which $X$ affects $Y$
]

.pull-right[

```{r, echo = F, fig.retina = 2, fig.align="center"}
dagify(Y~M,
               M~X,
                coords=list(
                x=c(X=1,Y=2, M=1.5),
                y=c(X=1,Y=1, M=1)
              )) %>% 
  tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```


]

---

# DAGs and Causal Effects

.pull-left[

- Arrows indicate causal effect (in proper direction)

- Two types of causal effect:

1. Direct effects $X \rightarrow Y$

2. Indirect effects $X \rightarrow M \rightarrow Y$ 
  - $M$ is a "mediator" variable, the mechanism by which $X$ affects $Y$

3. You of course might have both! 
]

.pull-right[

```{r, echo = F, fig.retina = 2, fig.align="center"}
dagify(Y~M+X,
               M~X,
                coords=list(
                x=c(X=1,Y=2, M=1.5),
                y=c(X=1,Y=1, M=2 )
              )) %>% 
  tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```


]

---

# Confounders

.pull-left[

- $Z$ is a .shout[confounder] of $X \rightarrow Y$, $Z$ affects both $X$ and $Y$

- $cor(X,Y)$ is made up of two parts:
    - The value of $Y$ is affected by the value of $X$ $(X \rightarrow Y$, good!)
    - $Z$ affects both the values of $X$ and $Y$ (A spurious correlation between $X$ and $Y$, bad!)  

- Failing to control for $Z$ will .whisper[bias] our estimate of the causal effect of $X \rightarrow Y$! 

]

.pull-right[

```{r, echo = F}
dagify(Y~Z+X,
       X~Z,
       coords=list(
         x=c(X=1,Y=2, Z=1.5),
         y=c(X=1,Y=1, Z=2)
         )) %>% 
  #tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# Confounders

.pull-left[

- Confounders are the DAG-equivalent of .shout[omitted variable bias]

- Biased regression $Y=\beta_0+\beta_1 X$ leaving out $Z$

- $\hat{\beta}_1$ picks up both:
  - $X \rightarrow Y$
  - $X \leftarrow Z \rightarrow Y$
]

.pull-right[

```{r, echo = F}
dagify(Y~Z+X,
       X~Z,
       coords=list(
         x=c(X=1,Y=2, Z=1.5),
         y=c(X=1,Y=1, Z=2)
         )) %>% 
  #tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# Front Doors and Back Doors

.pull-left[

- With this graph, there are two paths that connect $X$ and $Y$<sup>1</sup>:

1. A .shout[causal "front-door" path] $X \rightarrow Y$
    - Good, what we want to measure
    
2. A .shout[non-causal "back-door" path] $X \leftarrow Z \rightarrow Y$
    - At least one causal arrow runs in the opposite direction
    - Bad, adds a confounding bias

]

.pull-right[

```{r, echo = F}
dagify(Y~Z+X,
       X~Z,
       coords=list(
         x=c(X=1,Y=2, Z=1.5),
         y=c(X=1,Y=1, Z=2)
         )) %>% 
  #tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

.footnote[<sup>1</sup> Regardless of the directions of the arrows!]

---

# Controlling I 

.pull-left[

- If we can .onfire[control for] $Z$, we can *block* the back-door path $X \leftarrow Z \rightarrow Y$
    - Essentially, delete the arrow(s) connecting $X$, $Z$, and $Y$

- This would only leave the front-door, $X \rightarrow Y$

]

.pull-right[

```{r, echo = F}
dagify(Y~X,
       coords=list(
         x=c(X=1,Y=2),
         y=c(X=1,Y=1)
         )) %>% 
  #tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# Controlling II 

.pull-left[

- How to "control for" $Z$? We want to remove its influence over determining the values of $X$ and $Y$

- Multiple methods exist, but we've done this with .shout[multivariate regression]

- At the simplest level, consider only looking at values of $X$ and $Y$ for all observations that have the *same* value of $Z$
  - removes causal influence $Z$ has on $X$ and on $Y$
  - leaves only the influence $X$ has on $Y$!

]

.pull-right[

```{r, echo = F}
dagify(Y~X,
       coords=list(
         x=c(X=1,Y=2),
         y=c(X=1,Y=1)
         )) %>% 
  #tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]
---

# Controlling III

.pull-left[

- Controlling for a single variable along a long causal path is sufficient to block that path!

- Causal path: $X \rightarrow Y$
- Backdoor path: $X \leftarrow A \rightarrow B \rightarrow C \rightarrow Y$

- It is sufficient to block this backdoor by controlling **either** $A$ **or** $B$ **or** $C$!

]

.pull-right[

```{r, echo = F}
dagify(Y~X+C,
       X~A,
       B~A,
       C~B,
       coords=list(
         x=c(X=1,A=1.25, B=1.5, C=1.75, Y=2),
         y=c(X=1,A=1.5,B=1.5,C=1.5,Y=1)
         )) %>% 
  #tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```
]
---

# The Back Door Criterion

.pull-left[

- To achieve proper .onfire[identification] of the causal effect:

- The .shout["back-door criterion"]: control for the minimal amount of variables sufficient to ensure that no back-door exists between $X$ and $Y$

]

.pull-right[

```{r, echo = F}
dagify(Y~Z+X,
       X~Z,
       coords=list(
         x=c(X=1,Y=2, Z=1.5),
         y=c(X=1,Y=1, Z=2)
         )) %>% 
  #tidy_dagitty() %>%
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# The Back Door Criterion

.pull-left[

- Implications of the Back-door criterion:

1. You *only* need to control for the variables that keep a back-door open, *not all other variables!*

.content-box-green[
.green[**Example**]:

- $X \rightarrow Y$ (front-door)
- $X \leftarrow A \rightarrow B \rightarrow Y$ (back-door)

- Need only control for $A$ *or* $B$ to block the one back-door path
- $Z$ has no effect on $X$, and therefore we don't need to control for it! 

] 

]

.pull-right[

```{r, echo = F}
dagify(Y~X+B+Z,
       X~A,
       B~A) %>% 
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# The Back Door Criterion: Colliders

.pull-left[

- A case where controlling for a variable actually *adds bias* is if that variable is known as a .shout["collider"].

.content-box-green[
.green[**Example**]:

- $X \rightarrow Y$ (front-door)
- $X \leftarrow A \rightarrow B \leftarrow C \rightarrow Y$ (back-door, but **blocked by collider!**)

- $B$ is a collider because both $A$ and $C$ point to it
] 

- A collider automatically *blocks* a path
- If you control for the collider, it *opens* a path (bad idea if it's a backdoor path)

]

.pull-right[

```{r, echo = F}
dagify(Y~X+C,
       X~A,
       B~A+C,
       coords=list(
         x=c(X=1, A=1, B=1.5, C=2, Y=2),
         y=c(X=1, A=2, B=1.5, C=2, Y=1)
       )) %>% 
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# The Back Door Criterion: Colliders

.pull-left[

.content-box-green[
.green[**Example**]:

- $Flu$: getting the flu
- $Bus$: being hit by a bus
- $Hos$: being in the hospital

- Both $Flu$ and $Bus$ send you to $Hos$ (arrows)

- Knowing $Flu$ doesn't tell us about $Bus$ (no arrow)

- Conditional on being in $Hos$, negative association between $Flu$ and $Bus$ (spurious!) 
] 

]

.pull-right[

```{r, echo = F}
dagify(Hos~Flu+Bus,
       coords=list(
         x=c(Flu=1, Hos=1.5, Bus=2),
         y=c(Flu=1, Hos=2, Bus=1)
       )) %>% 
  ggdag_parents("Hos", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# Collider Example: Gender Discrimination I

.pull-left[

.content-box-green[
.green[**Example**]: How much of wage disparities are caused by gender-based discrimination?

1. $gender \rightarrow discr \rightarrow wage$ (Causal path)
2. $gender \rightarrow discr \rightarrow occup \rightarrow wage$ (Causal path)
3. $discr \leftarrow gender \rightarrow occup \rightarrow wage$ (Open back door)
4. $discr \leftarrow gender \rightarrow occup \leftarrow abil \rightarrow wage$ (BLOCKED back door!)
5. $gender \rightarrow discrim \rightarrow occup \leftarrow abil \rightarrow wage$ (BLOCKED back door!)

- Should we control for `occup`?
] 

]

.pull-right[

```{r, echo = F}
dagify(wage~abil+occup+discr,
       discr~gender,
       occup~gender+discr,
       exposure = "disc",
       outcome = "wage") %>% 
  ggdag_parents("wage", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# Collider Example: Gender Discrimination I

.pull-left[

- If leave occupation uncontrolled for: ignore non-discriminatory reasons different genders choose different occupations

- If we *control* for occupation:
  - opens backdoor paths 4 & 5!
  - creates spurious `cor(abil,discr)` where there wasn't one!
  - also closes causal path 2! (discriminatory reasons genders choose different occupations)
  
- **Can't identify causal effect** by controlling for `occup`!

- Research on this needs to get clever!

]

.pull-right[

```{r, echo = F}
dagify(wage~abil+occup+discr,
       discr~gender,
       occup~gender+discr,
       exposure = "disc",
       outcome = "wage") %>% 
  ggdag_parents("wage", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# The Front Door Criterion: Mediators

.pull-left[

- Another case where controlling for a variable actually *adds bias* is if that variable is known as a .shout["mediator"].

.content-box-green[
.green[**Example**]:

- $X \rightarrow M \rightarrow Y$ (front-door)
- $X \leftarrow A \rightarrow Y$ (back-door)
- $X \leftarrow B \rightarrow Y$ (back-door)

- Should we control for $M$? 
- If we did, this would block the front-door! 

- If we can estimate $X \rightarrow M$ and $M \rightarrow Y$ (note, no back-doors to either of these!), we can estimate $X \rightarrow Y$
] 

- This is the .whisper[front door method]

]

.pull-right[

```{r, echo = F}
dagify(Y~A+B+M,
       M~X,
       X~A+B,
       coords=list(
         x=c(X=1, A=1.5, B=1.5, M=1.5, Y=2),
         y=c(X=1, A=2, B=0, M=1, Y=1)
       )) %>% 
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

---

# Recap

.pull-left[

Thus, to achieve identification, control for the minimal amount of variables such that: 

1. Ensure that no back-door path remains open
    - Close back-door paths by controlling for a variable along that path
    - Colliders along a path automatically close that path

2. Ensure that no front-door path is closed

]

.pull-right[

```{r, echo = F}
dagify(Y~A+B+M,
       M~X,
       X~A+B,
       coords=list(
         x=c(X=1, A=1.5, B=1.5, M=1.5, Y=2),
         y=c(X=1, A=2, B=0, M=1, Y=1)
       )) %>% 
  ggdag_parents("Y", stylized = FALSE)+theme_dag_blank()+theme(legend.position = "none")
```

]

